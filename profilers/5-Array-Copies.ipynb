{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the internals of NumPy to avoid unnecessary array copying\n",
    "We can achieve significant performance speed enhancement with NumPy over native Python code, particularly when our computations follow the **Single Instruction, Multiple Data (SIMD)** paradigm.\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/SIMD2.svg/1920px-SIMD2.svg.png' width=300 align='left'>\n",
    "\n",
    "It describes computers with multiple processing elements that perform the same operation on multiple data points simultaneously. Such machines exploit data level parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def aid(x):\n",
    "    # This function returns the memory\n",
    "    # block address of an array.\n",
    "    return x.__array_interface__['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140627578758800, 140627578758808)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(3)\n",
    "aid(a), aid(a[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general and reliable solution to find out whether two arrays share the same data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_base(arr):\n",
    "    \"\"\"For a given Numpy array, find the base array\n",
    "    that owns the actual data.\"\"\"\n",
    "    base = arr\n",
    "    while isinstance(base.base, np.ndarray):\n",
    "        base = base.base\n",
    "    return base\n",
    "\n",
    "def arrays_share_data(x, y):\n",
    "    return get_data_base(x) is get_data_base(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(arrays_share_data(a, a.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(arrays_share_data(a, a[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it\n",
    "Computations with NumPy arrays may involve copies between blocks of memory. These copies are not always necessary, in which case they should be avoided.\n",
    "\n",
    "1. May need to make a copy of an array; e.g. if we need to manipulate an array while keeping an original copy in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140627609725040"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros(10)\n",
    "ax = aid(a)\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.copy()\n",
    "aid(b) == ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Array computations can involve in-place operations (the first example in the following code: the array is modified) or implicit-copy operations (the second example: a new array is created):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a *= 2\n",
    "aid(a) == ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a*2\n",
    "aid(c) == ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27 ms ± 19.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Explicity copy operations are slower\n",
    "%timeit a = np.zeros(1000000); a *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42 ms ± 52.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a = np.zeros(1000000); b = a * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Reshaping an array may or may not involve a copy. For instance, reshaping a 2D matrix does not involve a copy, unless it is transposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((100, 100))\n",
    "ax = aid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.reshape((1, -1))\n",
    "aid(b) == ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.T.reshape((1, -1))\n",
    "aid(c) == ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 ns ± 3.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# So the latter is significantly slower than the former\n",
    "%timeit b = a.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.79 µs ± 45.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a.T.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Both the `flatten()` and `ravel()` methods of an array reshape it into a 1D vector (a flattened array). However, the `flatten()` method always returns a copy, and the `ravel()` method returns a copy only if necessary (thus faster, especially with large arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = a.flatten()\n",
    "aid(d) == ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = a.ravel()\n",
    "aid(e) == ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.76 µs ± 43 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 ns ± 0.762 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Broadcasting rules** allow us to make computations on arrays with different but compatible shapes. In other words, we don't always need to reshape or tile our arrays to make their shapes match. The following example illustrates two ways of doing an **outer product** between two vectors: the first method involves array tiling, the second one (faster) involves broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "a = np.arange(n)\n",
    "ac = a[:, np.newaxis] # column vector\n",
    "ar = a[np.newaxis, :] # row vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.43 ms ± 103 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.tile(ac, (1, n)) * np.tile(ar, (n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 7.86 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ar * ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works\n",
    "### Why are NumPy arrays efficient?\n",
    "A Numpy array is basically described by metadata (notably the number of dimensions, the shape, and the data type) and the actual data.\n",
    "\n",
    "The data is stored in a **homogeneous** and **continguous** block of memory, at a particular address in system memory, at a particular address in system memory (**Random Access Memory (RAM)**). This block of memory is called the **data buffer**.\n",
    "\n",
    "This is the main difference between an array and a pure Python structure, such as a list, where the items are scattered across the system memory. This is the critical feature that makes NumPy arrays so efficient.\n",
    "\n",
    "Why is this so important? Main reasons:\n",
    "\n",
    "- Computations on arrays can be written very efficiently in a low language such as C (a large part of NumPy is actually written in C). Knowing the address of the memory block and the data type, it is just simple arithmetic to loop over all items, for examples. There would be a significant overhead if we did that in Python with a list.\n",
    "- **Spatial locality** in memory access patterns results in performance gains notably due to the CPU cache. Indeed, the cache loads bytes in chunks from the RAM to the CPU registers. Adjacent items are then loaded very efficiently (**sequential locality**, or **locality of reference**)\n",
    "- Finally, the fact that items are stored contiguously in memory allows NumPy and to take advantage of **vectorized instructions** of model CPUs, such as Intel's SSE and AVX, AMD's XOP and so on. E.g. multiple consecutive floating point numbers can be loaded in 128-, 256- or 512 bit registers for vectorized arithmetical computations implemented as CPU instructions.\n",
    "\n",
    "Additionally, NumPy can be linked to highly optimized linear algebra libraries such as `BLAS` and `LAPACK` through **ATLAS** or the **Intel Math Kernel Library (MKL)**. A few specific matrix computations may also be multithreaded, taking advantage of the power of modern multicore processors. \n",
    "\n",
    "In conclusion, storing data in a contiguous block of memory ensures that the architecture of modern CPUs is used optimally, in terms of memory access patterns, CPU cache, and vectorized instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the difference between in-place and implicit-copy operations?\n",
    "An expression such as `a *= 2` corresponds to an in-place operation, where all values of the array are multiplied by two. By contrast, `a = a*2` means that a new array containing the values of `a*2` is created, and the variable `a` now points to this new array. The old array becomes unreferenced and will be deleted by the garbage collector. No memory allocation happens in the first case, unlike the second case.\n",
    "\n",
    "More generally, expressions such as `a[i:j]` are views to parts of an array; the point to the memory buffer containing the data. Modifying them with inplace operations changes the original array.\n",
    "\n",
    "Knowing the subtlety of NumPy can help fix bugs and optimize the speed and memory consumption of your code by reducing the number of unnecessary copies.\n",
    "\n",
    "### Why can't some arrays be reshaped without a copy?\n",
    "We explain the example in step 3 here, where a transposed 2D matrix cannot be flattened without a copy. A 2D matrix contains items indexed by two numbers (row and column), but it is stored internally as a 1D contiguous block of memory: \n",
    "- **row-major order**: We can put the elements of the first row first, then the second row, and so on\n",
    "- **column-major order**: put the elements of the first column first, then second column...\n",
    "NumPy uses row-major order, like C, but unlike FORTRAN.\n",
    "\n",
    "<img src='numpy_order.png' width=300>\n",
    "\n",
    "More generally, NumPy uses the notion of **strides** to convert between a multidimensional index and the memory location of the underlying (1D) sequence of elements. The specific mapping between `array[i1, i2]` and the relevant byte address of the internal data is given by:\n",
    "\n",
    "```\n",
    "offset = array.strides[0] * i1 + array.strides[1] * i2\n",
    "```\n",
    "\n",
    "When reshaping an array, NumPy avoids copies when possible by modifying the **strides** attribute. For example, when transposing a matrix, the order of strides is reversed, but the underlying data remains identical. However, flattening a transposed array cannot be simply accomplished by modifying strides, so a copy is needed.\n",
    "\n",
    "Internal array layout can also explain unexpected performance discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.68 µs ± 75.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "34.8 µs ± 603 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(5000, 5000)\n",
    "%timeit a[0, :].sum()\n",
    "%timeit a[:, 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.8 µs ± 476 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a.T[0, :].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
